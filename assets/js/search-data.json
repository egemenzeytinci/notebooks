{
  
    
        "post0": {
            "title": "Visualization - Waffle Chart",
            "content": "Waffle Chart . A waffle chart is an interesting visualization that is normally created to display progress toward goals. It is commonly an effective option when you are trying to add interesting visualization features to a visual that consists mainly of cells, such as an Excel dashboard. . %%capture !pip3 install xlrd !pip3 install pywaffle . from pywaffle import Waffle import matplotlib.pyplot as plt import pandas as pd . df_can = pd.read_excel( &#39;./data/ibm/canada.xlsx&#39;, sheet_name=&#39;Canada by Citizenship&#39;, skiprows=range(20), skipfooter=2 ) . df_can.columns = list(map(lambda x: str(x), df_can.columns)) . drops = [ &#39;AREA&#39;, &#39;REG&#39;, &#39;DEV&#39;, &#39;Type&#39;, &#39;Coverage&#39; ] df_can.drop(columns=drops, inplace=True) . columns = { &#39;OdName&#39;: &#39;Country&#39;, &#39;AreaName&#39;: &#39;Continent&#39;, &#39;RegName&#39;: &#39;Region&#39; } df_can.rename(columns=columns, inplace=True) . df_can.set_index(&#39;Country&#39;, inplace=True) . df_can[&#39;Total&#39;] = df_can.sum(axis=1) . df_dsn = df_can.loc[[&#39;Denmark&#39;, &#39;Norway&#39;, &#39;Sweden&#39;], &#39;Total&#39;].reset_index() . totals = dict(zip(df_dsn.Country, df_dsn.Total / 100)) . fig = plt.figure( FigureClass=Waffle, rows=10, legend={&#39;loc&#39;: &#39;upper left&#39;, &#39;bbox_to_anchor&#39;: (1, 1)}, values=totals, figsize=(9, 5) ) plt.show() . fig = plt.figure( FigureClass=Waffle, rows=10, legend={&#39;loc&#39;: &#39;upper left&#39;, &#39;bbox_to_anchor&#39;: (1, 1)}, values=totals, icons=&#39;child&#39;, icon_legend=True, figsize=(9, 5) ) plt.show() . In the charts as above, 1 block = 100 individuals. .",
            "url": "https://egemenzeytinci.github.io/notebooks/ibm/visualization/waffle%20chart/2022/04/30/Waffle-Chart.html",
            "relUrl": "/ibm/visualization/waffle%20chart/2022/04/30/Waffle-Chart.html",
            "date": " • Apr 30, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Visualization - Subplots",
            "content": "Subplots . Often times we might want to plot multiple plots within the same figure. For example, we might want to perform a side by side comparison of the box plot with the line plot of China and India&#39;s immigration. . To visualize multiple plots together, we can create a figure (overall canvas) and divide it into subplots, each containing a plot. With subplots, we usually work with the artist layer instead of the scripting layer. . Typical syntax is : . fig = plt.figure() ax = fig.add_subplot(nrows, ncols, plot_number) . Where . nrows and ncols are used to notionally split the figure into (nrows * ncols) sub-axes, | plot_number is used to identify the particular subplot that this function is to create within the notional grid. plot_number starts at 1, increments across rows first and has a maximum of nrows * ncols as shown below. | . . %%capture !pip3 install xlrd . import matplotlib.pyplot as plt import pandas as pd . df_can = pd.read_excel( &#39;./data/ibm/canada.xlsx&#39;, sheet_name=&#39;Canada by Citizenship&#39;, skiprows=range(20), skipfooter=2 ) . df_can.columns = list(map(lambda x: str(x), df_can.columns)) . drops = [ &#39;AREA&#39;, &#39;REG&#39;, &#39;DEV&#39;, &#39;Type&#39;, &#39;Coverage&#39; ] df_can.drop(columns=drops, inplace=True) . columns = { &#39;OdName&#39;: &#39;Country&#39;, &#39;AreaName&#39;: &#39;Continent&#39;, &#39;RegName&#39;: &#39;Region&#39; } df_can.rename(columns=columns, inplace=True) . df_can.set_index(&#39;Country&#39;, inplace=True) . df_can[&#39;Total&#39;] = df_can.sum(axis=1) . /var/folders/s5/lzcc_1614bq9rypw8vg_pf7r0000gn/T/ipykernel_27997/552165185.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with &#39;numeric_only=None&#39;) is deprecated; in a future version this will raise TypeError. Select only valid columns before calling the reduction. df_can[&#39;Total&#39;] = df_can.sum(axis=1) . years = list(map(str, range(1980, 2014))) . df_ci = df_can.loc[[&#39;China&#39;, &#39;India&#39;], years].transpose() . fig = plt.figure() ax0 = fig.add_subplot(1, 2, 1) ax1 = fig.add_subplot(1, 2, 2) df_ci.plot(kind=&#39;box&#39;, color=&#39;blue&#39;, vert=False, figsize=(20, 6), ax=ax0) ax0.set_title(&#39;Box Plots of Immigrants from China and India (1980 - 2013)&#39;) ax0.set_xlabel(&#39;Number of Immigrants&#39;) ax0.set_ylabel(&#39;Countries&#39;) df_ci.plot(kind=&#39;line&#39;, figsize=(20, 6), ax=ax1) ax1.set_title (&#39;Line Plots of Immigrants from China and India (1980 - 2013)&#39;) ax1.set_ylabel(&#39;Number of Immigrants&#39;) ax1.set_xlabel(&#39;Years&#39;) plt.show() . Tip regarding subplot convention . In the case when nrows, ncols, and plot_number are all less than 10, a convenience exists such that the a 3 digit number can be given instead, where the hundreds represent nrows, the tens represent ncols and the units represent plot_number. For instance, . subplot(211) == subplot(2, 1, 1) . produces a subaxes in a figure which represents the top plot (i.e. the first) in a 2 rows by 1 column notional grid (no grid actually exists, but conceptually this is how the returned subplot has been positioned). .",
            "url": "https://egemenzeytinci.github.io/notebooks/ibm/visualization/subplots/2022/04/30/Subplots.html",
            "relUrl": "/ibm/visualization/subplots/2022/04/30/Subplots.html",
            "date": " • Apr 30, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "Visualization - Pie Chart",
            "content": "Pie Chart . A pie chart is a circualr graphic that displays numeric proportions by dividing a circle (or pie) into proportional slices. You are most likely already familiar with pie charts as it is widely used in business and media. We can create pie charts in Matplotlib by passing in the kind=pie keyword. . %%capture !pip3 install xlrd . import matplotlib.pyplot as plt import pandas as pd . df_can = pd.read_excel( &#39;./data/ibm/canada.xlsx&#39;, sheet_name=&#39;Canada by Citizenship&#39;, skiprows=range(20), skipfooter=2 ) . df_can.columns = list(map(lambda x: str(x), df_can.columns)) . drops = [ &#39;AREA&#39;, &#39;REG&#39;, &#39;DEV&#39;, &#39;Type&#39;, &#39;Coverage&#39; ] df_can.drop(columns=drops, inplace=True) . columns = { &#39;OdName&#39;: &#39;Country&#39;, &#39;AreaName&#39;: &#39;Continent&#39;, &#39;RegName&#39;: &#39;Region&#39; } df_can.rename(columns=columns, inplace=True) . df_can.set_index(&#39;Country&#39;, inplace=True) . df_can[&#39;Total&#39;] = df_can.sum(axis=1) . df_continents = df_can.groupby(&#39;Continent&#39;, axis=0).sum() . Remove the text labels on the pie chart by passing in legend and add it as a seperate legend using plt.legend(). | Push out the percentages to sit just outside the pie chart by passing in pctdistance parameter. | Pass in a custom set of colors for continents by passing in colors parameter. | Explode the pie chart to emphasize the lowest three continents (Africa, North America, and Latin America and Carribbean) by pasing in explode parameter. | . colors_list = [ &#39;gold&#39;, &#39;yellowgreen&#39;, &#39;lightcoral&#39;, &#39;lightskyblue&#39;, &#39;lightgreen&#39;, &#39;pink&#39; ] explode_list = [0.1, 0, 0, 0, 0.1, 0.1] df_continents[&#39;Total&#39;].plot( kind=&#39;pie&#39;, figsize=(15, 6), autopct=&#39;%1.1f%%&#39;, startangle=90, shadow=True, labels=None, pctdistance=1.12, colors=colors_list, explode=explode_list ) plt.title(&#39;Immigration to Canada by Continent [1980 - 2013]&#39;, y=1.12) plt.axis(&#39;equal&#39;) plt.legend(labels=df_continents.index, loc=&#39;upper left&#39;) plt.show() .",
            "url": "https://egemenzeytinci.github.io/notebooks/ibm/visualization/pie%20chart/2022/04/30/Pie-Chart.html",
            "relUrl": "/ibm/visualization/pie%20chart/2022/04/30/Pie-Chart.html",
            "date": " • Apr 30, 2022"
        }
        
    
  
    
        ,"post3": {
            "title": "Logistic Regression",
            "content": "from sklearn.linear_model import LogisticRegression from sklearn.metrics import ( confusion_matrix, classification_report, jaccard_score, log_loss ) from sklearn.model_selection import train_test_split from sklearn.preprocessing import StandardScaler import numpy as np import pandas as pd . df = pd.read_csv(&#39;./data/ibm/churn_data.csv&#39;) . columns = [ &#39;tenure&#39;, &#39;age&#39;, &#39;address&#39;, &#39;income&#39;, &#39;ed&#39;, &#39;employ&#39;, &#39;equip&#39;, &#39;callcard&#39;, &#39;wireless&#39;, &#39;churn&#39; ] . churn = df[columns].copy() churn[&#39;churn&#39;] = churn[&#39;churn&#39;].astype(&#39;int&#39;) . scaler = StandardScaler() . columns = [ &#39;tenure&#39;, &#39;age&#39;, &#39;address&#39;, &#39;income&#39;, &#39;ed&#39;, &#39;employ&#39;, &#39;equip&#39; ] . X = np.asarray(churn[columns]) X = scaler.fit_transform(X) . y = np.asarray(churn[&#39;churn&#39;]) . X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4) . lr = LogisticRegression(C=0.01, solver=&#39;liblinear&#39;).fit(X_train,y_train) . y_hat = lr.predict(X_test) y_hat_prob = lr.predict_proba(X_test) . confusion_matrix(y_test, y_hat) . array([[24, 1], [ 9, 6]]) . print(classification_report(y_test, y_hat)) . precision recall f1-score support 0 0.73 0.96 0.83 25 1 0.86 0.40 0.55 15 accuracy 0.75 40 macro avg 0.79 0.68 0.69 40 weighted avg 0.78 0.75 0.72 40 . Log loss . Now, lets try log loss for evaluation. In logistic regression, the output can be the probability of customer churn is yes (or equals to 1). This probability is a value between 0 and 1. Log loss( Logarithmic loss) measures the performance of a classifier where the predicted output is a probability value between 0 and 1. . log_loss(y_test, y_hat_prob) . 0.6017092478101185 .",
            "url": "https://egemenzeytinci.github.io/notebooks/ibm/classification/logistic%20regression/2022/04/30/Logistic-Regression.html",
            "relUrl": "/ibm/classification/logistic%20regression/2022/04/30/Logistic-Regression.html",
            "date": " • Apr 30, 2022"
        }
        
    
  
    
        ,"post4": {
            "title": "K-Means",
            "content": "Customer Segmentation with K-Means . Imagine that you have a customer dataset, and you need to apply customer segmentation on this historical data. Customer segmentation is the practice of partitioning a customer base into groups of individuals that have similar characteristics. It is a significant strategy as a business can target these specific groups of customers and effectively allocate marketing resources. For example, one group might contain customers who are high-profit and low-risk, that is, more likely to purchase products, or subscribe for a service. A business task is to retaining those customers. Another group might include customers from non-profit organizations. And so on. . from sklearn.preprocessing import StandardScaler from sklearn.cluster import KMeans import matplotlib.pyplot as plt import numpy as np import pandas as pd . df = pd.read_csv(&#39;./data/ibm/customer_segmentation.csv&#39;) . customers = df.drop(&#39;Address&#39;, axis=1) . X = customers.values[:,1:] X = np.nan_to_num(X) dataset = StandardScaler().fit_transform(X) . In our example (if we didn&#39;t have access to the k-means algorithm), it would be the same as guessing that each customer group would have certain age, income, education, etc, with multiple tests and experiments. However, using the K-means clustering we can do all this process much easier. . Lets apply k-means on our dataset, and take look at cluster labels. . num_of_clusters = 3 k_means = KMeans(init=&#39;k-means++&#39;, n_clusters=num_of_clusters, n_init=12) k_means.fit(X) labels = k_means.labels_ . customers[&#39;cluster&#39;] = labels . area = np.pi * (X[:, 1]) ** 2 plt.scatter(X[:, 0], X[:, 3], s=area, c=labels.astype(np.float), alpha=0.5) plt.xlabel(&#39;Age&#39;, fontsize=18) plt.ylabel(&#39;Income&#39;, fontsize=16) plt.show() . from mpl_toolkits.mplot3d import Axes3D fig = plt.figure(1, figsize=(8, 6)) plt.clf() ax = Axes3D(fig, rect=[0, 0, .95, 1], elev=48, azim=134) plt.cla() ax.set_xlabel(&#39;Education&#39;) ax.set_ylabel(&#39;Age&#39;) ax.set_zlabel(&#39;Income&#39;) ax.scatter(X[:, 1], X[:, 0], X[:, 3], c= labels.astype(np.float)); . k-means will partition your customers into mutually exclusive groups, for example, into 3 clusters. The customers in each cluster are similar to each other demographically. Now we can create a profile for each group, considering the common characteristics of each cluster. For example, the 3 clusters can be: . AFFLUENT, EDUCATED AND OLD AGED | MIDDLE AGED AND MIDDLE INCOME | YOUNG AND LOW INCOME | .",
            "url": "https://egemenzeytinci.github.io/notebooks/ibm/clustering/kmeans/2022/04/30/Kmeans.html",
            "relUrl": "/ibm/clustering/kmeans/2022/04/30/Kmeans.html",
            "date": " • Apr 30, 2022"
        }
        
    
  
    
        ,"post5": {
            "title": "Visualization - Histogram",
            "content": "Histogram . A histogram is a way of representing the frequency distribution of numeric dataset. The way it works is it partitions the x-axis into bins, assigns each data point in our dataset to a bin, and then counts the number of data points that have been assigned to each bin. So the y-axis is the frequency or the number of data points in each bin. Note that we can change the bin size and usually one needs to tweak it so that the distribution is displayed nicely. . %%capture !pip3 install xlrd . import pandas as pd import matplotlib.pyplot as plt import numpy as np . df_can = pd.read_excel( &#39;./data/ibm/canada.xlsx&#39;, sheet_name=&#39;Canada by Citizenship&#39;, skiprows=range(20), skipfooter=2 ) . df_can.columns = list(map(lambda x: str(x), df_can.columns)) . drops = [ &#39;AREA&#39;, &#39;REG&#39;, &#39;DEV&#39;, &#39;Type&#39;, &#39;Coverage&#39; ] df_can.drop(columns=drops, inplace=True) . columns = { &#39;OdName&#39;: &#39;Country&#39;, &#39;AreaName&#39;: &#39;Continent&#39;, &#39;RegName&#39;: &#39;Region&#39; } df_can.rename(columns=columns, inplace=True) . df_can.set_index(&#39;Country&#39;, inplace=True) . df_can[&#39;Total&#39;] = df_can.sum(axis=1) . df_can[&#39;2013&#39;].plot(kind=&#39;hist&#39;, figsize=(8, 5)) plt.title(&#39;Histogram of Immigration from 195 Countries in 2013&#39;) plt.ylabel(&#39;Number of Countries&#39;) plt.xlabel(&#39;Number of Immigrants&#39;) plt.show() . In the above plot, the x-axis represents the population range of immigrants in intervals of 3412.9. The y-axis represents the number of countries that contributed to the aforementioned population. . Notice that the x-axis labels do not match with the bin size. This can be fixed by passing in a xticks keyword that contains the list of the bin sizes, as follows: . count, bin_edges = np.histogram(df_can[&#39;2013&#39;]) df_can[&#39;2013&#39;].plot(kind=&#39;hist&#39;, figsize=(8, 5), xticks=bin_edges) plt.title(&#39;Histogram of Immigration from 195 countries in 2013&#39;) plt.ylabel(&#39;Number of Countries&#39;) plt.xlabel(&#39;Number of Immigrants&#39;) plt.show() .",
            "url": "https://egemenzeytinci.github.io/notebooks/ibm/visualization/histogram/2022/04/30/Histogram.html",
            "relUrl": "/ibm/visualization/histogram/2022/04/30/Histogram.html",
            "date": " • Apr 30, 2022"
        }
        
    
  
    
        ,"post6": {
            "title": "Hierarchical Clustering",
            "content": "Hierarchical Clustering - Agglomerative . from matplotlib.axes._axes import _log as matplotlib_axes_logger from scipy.cluster.hierarchy import dendrogram, linkage, fcluster from scipy.spatial import distance_matrix from scipy.spatial.distance import euclidean from sklearn.cluster import AgglomerativeClustering from sklearn.preprocessing import MinMaxScaler import matplotlib.cm as cm import matplotlib.pyplot as plt import numpy as np import pandas as pd import pylab import scipy import warnings matplotlib_axes_logger.setLevel(&#39;ERROR&#39;) warnings.filterwarnings(&#39;ignore&#39;) . df = pd.read_csv(&#39;./data/ibm/cars_clus.csv&#39;) . columns = [ &#39;sales&#39;, &#39;resale&#39;, &#39;type&#39;, &#39;price&#39;, &#39;engine_s&#39;, &#39;horsepow&#39;, &#39;wheelbas&#39;, &#39;width&#39;, &#39;length&#39;, &#39;curb_wgt&#39;, &#39;fuel_cap&#39;, &#39;mpg&#39;, &#39;lnsales&#39; ] df[columns] = df[columns].apply(pd.to_numeric, errors=&#39;coerce&#39;) . df = df.dropna() df = df.reset_index(drop=True) . columns = [ &#39;engine_s&#39;, &#39;horsepow&#39;, &#39;wheelbas&#39;, &#39;width&#39;, &#39;length&#39;, &#39;curb_wgt&#39;, &#39;fuel_cap&#39;, &#39;mpg&#39; ] dataset = df[columns] . X = dataset.values mms = MinMaxScaler() features = mms.fit_transform(X) . leng = features.shape[0] D = scipy.zeros([leng, leng]) for i in range(leng): for j in range(leng): D[i,j] = euclidean(features[i], features[j]) . Z = linkage(D, &#39;complete&#39;) . k = 3 clusters = fcluster(Z, k, criterion=&#39;distance&#39;) . def llf(id): return &#39;[%s %s %s]&#39; % (df[&#39;manufact&#39;][id], df[&#39;model&#39;][id], int(float(df[&#39;type&#39;][id]))) . fig = pylab.figure(figsize=(18,50)) dendro = dendrogram(Z, leaf_label_func=llf, leaf_rotation=0, leaf_font_size=12, orientation=&#39;right&#39;) . Clustering using scikit-learn . Now, we can use the &#39;AgglomerativeClustering&#39; function from scikit-learn library to cluster the dataset. The AgglomerativeClustering performs a hierarchical clustering using a bottom up approach. The linkage criteria determines the metric used for the merge strategy: . Ward minimizes the sum of squared differences within all clusters. It is a variance-minimizing approach and in this sense is similar to the k-means objective function but tackled with an agglomerative hierarchical approach. | Maximum or complete linkage minimizes the maximum distance between observations of pairs of clusters. | Average linkage minimizes the average of the distances between all observations of pairs of clusters. | . dist_matrix = distance_matrix(features, features) . agglom = AgglomerativeClustering(n_clusters=6, linkage=&#39;complete&#39;) . agglom.fit(features) . AgglomerativeClustering(linkage=&#39;complete&#39;, n_clusters=6) . df[&#39;cluster&#39;] = agglom.labels_ . n_clusters = max(agglom.labels_) + 1 colors = cm.rainbow(np.linspace(0, 1, n_clusters)) cluster_labels = list(range(0, n_clusters)) plt.figure(figsize=(16, 14)) for color, label in zip(colors, cluster_labels): subset = df[df.cluster == label] for i in subset.index: plt.text( subset.horsepow[i], subset.mpg[i], str(subset[&#39;model&#39;][i]), rotation=25 ) plt.scatter( subset.horsepow, subset.mpg, s= subset.price * 10, c=color, label=&#39;cluster&#39; + str(label), alpha=0.5 ) plt.legend() plt.title(&#39;Clusters&#39;) plt.xlabel(&#39;horsepow&#39;) plt.ylabel(&#39;mpg&#39;); . cols = [ &#39;horsepow&#39;, &#39;engine_s&#39;, &#39;mpg&#39;, &#39;price&#39; ] agg_cars = df.groupby([&#39;cluster&#39;, &#39;type&#39;])[cols].mean() agg_cars . horsepow engine_s mpg price . cluster type . 0 1.0 211.666667 | 4.483333 | 16.166667 | 29.024667 | . 1 0.0 146.531915 | 2.246809 | 27.021277 | 20.306128 | . 1.0 145.000000 | 2.580000 | 22.200000 | 17.009200 | . 2 0.0 203.111111 | 3.303704 | 24.214815 | 27.750593 | . 1.0 182.090909 | 3.345455 | 20.181818 | 26.265364 | . 3 0.0 256.500000 | 4.410000 | 21.500000 | 42.870400 | . 1.0 160.571429 | 3.071429 | 21.428571 | 21.527714 | . 4 0.0 55.000000 | 1.000000 | 45.000000 | 9.235000 | . 5 0.0 365.666667 | 6.233333 | 19.333333 | 66.010000 | . It is obvious that we have 3 main clusters with the majority of vehicles in those. . Cars: . Cluster 1: with almost high mpg, and low in horsepower. | Cluster 2: with good mpg and horsepower, but higher price than average. | Cluster 3: with low mpg, high horsepower, highest price. | . Trucks: . Cluster 1: with almost highest mpg among trucks, and lowest in horsepower and price. | Cluster 2: with almost low mpg and medium horsepower, but higher price than average. | Cluster 3: with good mpg and horsepower, low price. | . Please notice that we did not use type , and price of cars in the clustering process, but Hierarchical clustering could forge the clusters and discriminate them with quite high accuracy. . plt.figure(figsize=(16, 10)) for color, label in zip(colors, cluster_labels): subset = agg_cars.loc[(label,),] for i in subset.index: plt.text( subset.loc[i][0] + 5, subset.loc[i][2], &#39;type=&#39; + str(int(i)) + &#39;, price=&#39; + str(int(subset.loc[i][3])) + &#39;k&#39; ) plt.scatter(subset.horsepow, subset.mpg, s=subset.price*20, c=color, label=&#39;cluster&#39;+str(label)) plt.legend() plt.title(&#39;Clusters&#39;) plt.xlabel(&#39;horsepow&#39;) plt.ylabel(&#39;mpg&#39;); .",
            "url": "https://egemenzeytinci.github.io/notebooks/ibm/clustering/hierarchical%20clustering/2022/04/30/Hierarchical-Clustering.html",
            "relUrl": "/ibm/clustering/hierarchical%20clustering/2022/04/30/Hierarchical-Clustering.html",
            "date": " • Apr 30, 2022"
        }
        
    
  
    
        ,"post7": {
            "title": "Visualization - Bubble Plot",
            "content": "Bubble Plot . A bubble plot is a variation of the scatter plot that displays three dimensions of data (x, y, z). The datapoints are replaced with bubbles, and the size of the bubble is determined by the third variable &#39;z&#39;, also known as the weight. In maplotlib, we can pass in an array or scalar to the keyword s to plot(), that contains the weight of each point. . %%capture !pip3 install xlrd . import matplotlib.pyplot as plt import pandas as pd . df_can = pd.read_excel( &#39;./data/ibm/canada.xlsx&#39;, sheet_name=&#39;Canada by Citizenship&#39;, skiprows=range(20), skipfooter=2 ) . df_can.columns = list(map(lambda x: str(x), df_can.columns)) . drops = [ &#39;AREA&#39;, &#39;REG&#39;, &#39;DEV&#39;, &#39;Type&#39;, &#39;Coverage&#39; ] df_can.drop(columns=drops, inplace=True) . columns = { &#39;OdName&#39;: &#39;Country&#39;, &#39;AreaName&#39;: &#39;Continent&#39;, &#39;RegName&#39;: &#39;Region&#39; } df_can.rename(columns=columns, inplace=True) . df_can.set_index(&#39;Country&#39;, inplace=True) . df_can[&#39;Total&#39;] = df_can.sum(axis=1) . years = list(map(str, range(1980, 2014))) . df_can_t = df_can[years].transpose() df_can_t.index = map(int, df_can_t.index) df_can_t.index.name = &#39;Year&#39; df_can_t.reset_index(inplace=True) . def normalize(data, col): return (data[col] - data[col].min()) / (data[col].max() - data[col].min()) . norm_brazil = normalize(df_can_t, &#39;Brazil&#39;) norm_argentina = normalize(df_can_t, &#39;Argentina&#39;) . ax0 = df_can_t.plot( kind=&#39;scatter&#39;, x=&#39;Year&#39;, y=&#39;Brazil&#39;, figsize=(14, 8), alpha=0.5, color=&#39;green&#39;, s=norm_brazil * 2000 + 10, xlim=(1975, 2015) ) ax1 = df_can_t.plot( kind=&#39;scatter&#39;, x=&#39;Year&#39;, y=&#39;Argentina&#39;, alpha=0.5, color=&#39;blue&#39;, s=norm_argentina * 2000 + 10, ax = ax0 ) ax0.set_ylabel(&#39;Number of Immigrants&#39;) ax0.set_title(&#39;Immigration from Brazil and Argentina from 1980 - 2013&#39;) ax0.legend([&#39;Brazil&#39;, &#39;Argentina&#39;], loc=&#39;upper left&#39;, fontsize=&#39;x-large&#39;) . &lt;matplotlib.legend.Legend at 0x116f1da20&gt; . The size of the bubble corresponds to the magnitude of immigrating population for that year, compared to the 1980 - 2013 data. The larger the bubble, the more immigrants in that year. . From the plot above, we can see a corresponding increase in immigration from Argentina during the 1998 - 2002 great depression. We can also observe a similar spike around 1985 to 1993. In fact, Argentina had suffered a great depression from 1974 - 1990, just before the onset of 1998 - 2002 great depression. . On a similar note, Brazil suffered the Samba Effect where the Brazilian real (currency) dropped nearly 35% in 1999. There was a fear of a South American financial crisis as many South American countries were heavily dependent on industrial exports from Brazil. The Brazilian government subsequently adopted an austerity program, and the economy slowly recovered over the years, culminating in a surge in 2010. The immigration data reflect these events. .",
            "url": "https://egemenzeytinci.github.io/notebooks/ibm/visualization/bubble%20plot/2022/04/30/Bubble-Plot.html",
            "relUrl": "/ibm/visualization/bubble%20plot/2022/04/30/Bubble-Plot.html",
            "date": " • Apr 30, 2022"
        }
        
    
  
    
        ,"post8": {
            "title": "Visualization - Area Plot",
            "content": "Area Plot . %%capture !pip3 install xlrd . import matplotlib.pyplot as plt import pandas as pd . df_can = pd.read_excel( &#39;./data/ibm/canada.xlsx&#39;, sheet_name=&#39;Canada by Citizenship&#39;, skiprows=range(20), skipfooter=2 ) . df_can.columns = list(map(lambda x: str(x), df_can.columns)) . drops = [ &#39;AREA&#39;, &#39;REG&#39;, &#39;DEV&#39;, &#39;Type&#39;, &#39;Coverage&#39; ] df_can.drop(columns=drops, inplace=True) . columns = { &#39;OdName&#39;: &#39;Country&#39;, &#39;AreaName&#39;: &#39;Continent&#39;, &#39;RegName&#39;: &#39;Region&#39; } df_can.rename(columns=columns, inplace=True) . df_can.set_index(&#39;Country&#39;, inplace=True) . df_can[&#39;Total&#39;] = df_can.sum(axis=1) . years = list(map(str, range(1980, 2014))) . df_can.sort_values(&#39;Total&#39;, ascending=False, axis=0, inplace=True) df_top5 = df_can.head() df_top5 = df_top5[years].transpose() df_top5.head() . Country India China United Kingdom of Great Britain and Northern Ireland Philippines Pakistan . 1980 8880 | 5123 | 22045 | 6051 | 978 | . 1981 8670 | 6682 | 24796 | 5921 | 972 | . 1982 8147 | 3308 | 20620 | 5249 | 1201 | . 1983 7338 | 1863 | 10015 | 4562 | 900 | . 1984 5704 | 1527 | 10170 | 3801 | 668 | . df_top5.index = df_top5.index.map(int) df_top5.plot( kind=&#39;area&#39;, stacked=False, figsize=(20, 10) ) plt.title(&#39;Immigration Trend of Top 5 Countries&#39;) plt.ylabel(&#39;Number of Immigrants&#39;) plt.xlabel(&#39;Years&#39;) plt.show() . The unstacked plot has a default transparency (alpha value) at 0.5. We can modify this value by passing in the alpha parameter. . df_top5.plot( kind=&#39;area&#39;, alpha=0.25, stacked=False, figsize=(20, 10), ) plt.title(&#39;Immigration Trend of Top 5 Countries&#39;) plt.ylabel(&#39;Number of Immigrants&#39;) plt.xlabel(&#39;Years&#39;) plt.show() . Two types of plotting . There are two styles/options of ploting with matplotlib. Plotting using the Artist layer and plotting using the scripting layer. . Option 1: Scripting layer (procedural method) - using matplotlib.pyplot as plt . You can use plt i.e. matplotlib.pyplot and add more elements by calling different methods procedurally; for example, plt.title(...) to add title or plt.xlabel(...) to add label to the x-axis. . # option 1: this is what we have been using so far df_top5.plot(kind=&#39;area&#39;, alpha=0.35, figsize=(20, 10)) plt.title(&#39;Immigration trend of top 5 countries&#39;) plt.ylabel(&#39;Number of immigrants&#39;) plt.xlabel(&#39;Years&#39;) . Option 2: Artist layer (Object oriented method) - using an Axes instance from Matplotlib (preferred) . You can use an Axes instance of your current plot and store it in a variable (eg. ax). You can add more elements by calling methods with a little change in syntax (by adding *set_* to the previous methods). For example, use ax.set_title() instead of plt.title() to add title, or ax.set_xlabel() instead of plt.xlabel() to add label to the x-axis. . This option sometimes is more transparent and flexible to use for advanced plots. . # option 2: preferred option with more flexibility ax = df_top5.plot(kind=&#39;area&#39;, alpha=0.35, figsize=(20, 10)) ax.set_title(&#39;Immigration Trend of Top 5 Countries&#39;) ax.set_ylabel(&#39;Number of Immigrants&#39;) ax.set_xlabel(&#39;Years&#39;) .",
            "url": "https://egemenzeytinci.github.io/notebooks/ibm/visualization/area%20plot/2022/04/30/Area-Plot.html",
            "relUrl": "/ibm/visualization/area%20plot/2022/04/30/Area-Plot.html",
            "date": " • Apr 30, 2022"
        }
        
    
  

  
  

  

  
  

  

  
  

  

  
  

  
  

  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://egemenzeytinci.github.io/notebooks/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}